{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOLIDAYS GRANULAR (programa_letra):\n",
      "  Total filas:  1110\n",
      "  Tipos únicos: 81\n",
      "  Ejemplo: <StringArray>\n",
      "[    'adultos_mayores_A',        'discapacidad_A', 'madres_trabajadoras_A',\n",
      "     'adultos_mayores_B',        'discapacidad_B']\n",
      "Length: 5, dtype: str\n",
      "\n",
      "HOLIDAYS AGREGADO (solo programa):\n",
      "  Total filas:  615\n",
      "  Tipos únicos: 3\n",
      "  Tipos: <StringArray>\n",
      "['adultos_mayores', 'discapacidad', 'madres_trabajadoras']\n",
      "Length: 3, dtype: str\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import pyarrow.parquet as pq\n",
    "# pip install neuralprophet\n",
    "df = pd.read_parquet(\"C://Users//diana.lara//Documents//GitHub//Prophet_banco_bienestar//Insumos//df_general.parquet\", engine=\"fastparquet\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CALENDARIOS OFICIALES COMPLETOS (nov 2023 - ene 2026)\n",
    "# ============================================================\n",
    "\n",
    "# Calendarios con fechas EXACTAS verificadas en fuentes oficiales\n",
    "calendarios_exactos = {\n",
    "    # Nov-Dic 2023: 6-30 noviembre\n",
    "    '2023-11': [\n",
    "        ('2023-11-06', ['A']),\n",
    "        ('2023-11-07', ['B']),\n",
    "        ('2023-11-08', ['C']),\n",
    "        ('2023-11-09', ['C']),\n",
    "        ('2023-11-10', ['D','E','F']),\n",
    "        ('2023-11-13', ['G']),\n",
    "        ('2023-11-14', ['G']),\n",
    "        ('2023-11-15', ['H','I','J','K']),\n",
    "        ('2023-11-16', ['L']),\n",
    "        ('2023-11-17', ['M']),\n",
    "        ('2023-11-21', ['M']),\n",
    "        ('2023-11-22', ['N','Ñ','O']),\n",
    "        ('2023-11-23', ['P','Q']),\n",
    "        ('2023-11-24', ['R']),\n",
    "        ('2023-11-27', ['R']),\n",
    "        ('2023-11-28', ['S']),\n",
    "        ('2023-11-29', ['T','U']),\n",
    "        ('2023-11-30', ['V','W','X','Y','Z']),\n",
    "    ],\n",
    "\n",
    "    # Ene-Feb 2024 ELECTORAL: 29 enero - 23 febrero (pago doble mar-abr + may-jun)\n",
    "    '2024-01-electoral': [\n",
    "        ('2024-01-29', ['A']),\n",
    "        ('2024-01-30', ['B']),\n",
    "        ('2024-01-31', ['C']),\n",
    "        ('2024-02-01', ['C']),\n",
    "        ('2024-02-02', ['D','E','F']),\n",
    "        ('2024-02-06', ['G']),\n",
    "        ('2024-02-07', ['G']),\n",
    "        ('2024-02-08', ['H']),\n",
    "        ('2024-02-09', ['I','J','K']),\n",
    "        ('2024-02-12', ['L']),\n",
    "        ('2024-02-13', ['M']),\n",
    "        ('2024-02-14', ['M']),\n",
    "        ('2024-02-15', ['N','Ñ','O']),\n",
    "        ('2024-02-16', ['P','Q']),\n",
    "        ('2024-02-19', ['R']),\n",
    "        ('2024-02-20', ['R']),\n",
    "        ('2024-02-21', ['S']),\n",
    "        ('2024-02-22', ['T','U']),\n",
    "        ('2024-02-23', ['V','W','X','Y','Z']),\n",
    "    ],\n",
    "\n",
    "    # Jul-Ago 2024: 1-22 julio\n",
    "    '2024-07': [\n",
    "        ('2024-07-01', ['A']),\n",
    "        ('2024-07-02', ['B']),\n",
    "        ('2024-07-03', ['C']),\n",
    "        ('2024-07-04', ['C']),\n",
    "        ('2024-07-05', ['D','E','F']),\n",
    "        ('2024-07-08', ['G']),\n",
    "        ('2024-07-09', ['G']),\n",
    "        ('2024-07-10', ['H','I','J','K']),\n",
    "        ('2024-07-11', ['L']),\n",
    "        ('2024-07-12', ['M']),\n",
    "        ('2024-07-15', ['M']),\n",
    "        ('2024-07-16', ['N','Ñ','O']),\n",
    "        ('2024-07-17', ['P','Q']),\n",
    "        ('2024-07-18', ['R']),\n",
    "        ('2024-07-19', ['R']),\n",
    "        ('2024-07-22', ['S','T','U','V','W','X','Y','Z']),\n",
    "    ],\n",
    "\n",
    "    # Sep-Oct 2024: 2-20 septiembre\n",
    "    '2024-09': [\n",
    "        ('2024-09-02', ['A']),\n",
    "        ('2024-09-03', ['B']),\n",
    "        ('2024-09-04', ['C']),\n",
    "        ('2024-09-05', ['C']),\n",
    "        ('2024-09-06', ['D','E','F']),\n",
    "        ('2024-09-09', ['G']),\n",
    "        ('2024-09-10', ['G']),\n",
    "        ('2024-09-11', ['H','I','J','K']),\n",
    "        ('2024-09-12', ['L']),\n",
    "        ('2024-09-13', ['M']),\n",
    "        ('2024-09-17', ['M']),\n",
    "        ('2024-09-18', ['N','Ñ','O']),\n",
    "        ('2024-09-19', ['P','Q']),\n",
    "        ('2024-09-20', ['R','S','T','U','V','W','X','Y','Z']),\n",
    "    ],\n",
    "\n",
    "    # Nov-Dic 2024: 4-28 noviembre\n",
    "    '2024-11': [\n",
    "        ('2024-11-04', ['A']),\n",
    "        ('2024-11-05', ['B']),\n",
    "        ('2024-11-06', ['C']),\n",
    "        ('2024-11-07', ['C']),\n",
    "        ('2024-11-08', ['D','E','F']),\n",
    "        ('2024-11-11', ['G']),\n",
    "        ('2024-11-12', ['G']),\n",
    "        ('2024-11-13', ['H','I','J','K']),\n",
    "        ('2024-11-14', ['L']),\n",
    "        ('2024-11-15', ['M']),\n",
    "        ('2024-11-19', ['M']),\n",
    "        ('2024-11-20', ['N','Ñ','O']),\n",
    "        ('2024-11-21', ['P','Q']),\n",
    "        ('2024-11-22', ['R']),\n",
    "        ('2024-11-25', ['R']),\n",
    "        ('2024-11-26', ['S']),\n",
    "        ('2024-11-27', ['T','U','V']),\n",
    "        ('2024-11-28', ['W','X','Y','Z']),\n",
    "    ],\n",
    "\n",
    "    # Ene-Feb 2025: 2-22 enero\n",
    "    '2025-01': [\n",
    "        ('2025-01-02', ['A']),\n",
    "        ('2025-01-03', ['B']),\n",
    "        ('2025-01-06', ['C']),\n",
    "        ('2025-01-07', ['C']),\n",
    "        ('2025-01-08', ['D','E','F']),\n",
    "        ('2025-01-09', ['G']),\n",
    "        ('2025-01-10', ['G']),\n",
    "        ('2025-01-13', ['H','I','J','K']),\n",
    "        ('2025-01-14', ['L']),\n",
    "        ('2025-01-15', ['M']),\n",
    "        ('2025-01-16', ['M']),\n",
    "        ('2025-01-17', ['N','Ñ','O']),\n",
    "        ('2025-01-20', ['P','Q']),\n",
    "        ('2025-01-21', ['R']),\n",
    "        ('2025-01-22', ['S','T','U','V','W','X','Y','Z']),\n",
    "    ],\n",
    "\n",
    "    # Mar-Abr 2025: 3-27 marzo\n",
    "    '2025-03': [\n",
    "        ('2025-03-03', ['A']),\n",
    "        ('2025-03-04', ['B']),\n",
    "        ('2025-03-05', ['C']),\n",
    "        ('2025-03-06', ['C']),\n",
    "        ('2025-03-07', ['D','E','F']),\n",
    "        ('2025-03-10', ['G']),\n",
    "        ('2025-03-11', ['G']),\n",
    "        ('2025-03-12', ['H','I','J','K']),\n",
    "        ('2025-03-13', ['L']),\n",
    "        ('2025-03-14', ['M']),\n",
    "        ('2025-03-17', ['M']),\n",
    "        ('2025-03-18', ['N','Ñ','O']),\n",
    "        ('2025-03-19', ['P','Q']),\n",
    "        ('2025-03-20', ['R']),\n",
    "        ('2025-03-24', ['R']),\n",
    "        ('2025-03-25', ['S']),\n",
    "        ('2025-03-26', ['T','U','V']),\n",
    "        ('2025-03-27', ['W','X','Y','Z']),\n",
    "    ],\n",
    "\n",
    "    # May-Jun 2025: 7-30 mayo\n",
    "    '2025-05': [\n",
    "        ('2025-05-07', ['A']),\n",
    "        ('2025-05-08', ['B']),\n",
    "        ('2025-05-09', ['C']),\n",
    "        ('2025-05-12', ['C']),\n",
    "        ('2025-05-13', ['D','E','F']),\n",
    "        ('2025-05-14', ['G']),\n",
    "        ('2025-05-15', ['G']),\n",
    "        ('2025-05-16', ['H','I','J','K']),\n",
    "        ('2025-05-19', ['L']),\n",
    "        ('2025-05-20', ['M']),\n",
    "        ('2025-05-21', ['M']),\n",
    "        ('2025-05-22', ['N','Ñ','O']),\n",
    "        ('2025-05-23', ['P','Q']),\n",
    "        ('2025-05-26', ['R']),\n",
    "        ('2025-05-27', ['R']),\n",
    "        ('2025-05-28', ['S']),\n",
    "        ('2025-05-29', ['T','U','V']),\n",
    "        ('2025-05-30', ['W','X','Y','Z']),\n",
    "    ],\n",
    "\n",
    "    # Jul-Ago 2025: 1-24 julio\n",
    "    '2025-07': [\n",
    "        ('2025-07-01', ['A']),\n",
    "        ('2025-07-02', ['B']),\n",
    "        ('2025-07-03', ['C']),\n",
    "        ('2025-07-04', ['C']),\n",
    "        ('2025-07-07', ['D','E','F']),\n",
    "        ('2025-07-08', ['G']),\n",
    "        ('2025-07-09', ['G']),\n",
    "        ('2025-07-10', ['H','I','J','K']),\n",
    "        ('2025-07-11', ['L']),\n",
    "        ('2025-07-14', ['M']),\n",
    "        ('2025-07-15', ['M']),\n",
    "        ('2025-07-16', ['N','Ñ','O']),\n",
    "        ('2025-07-17', ['P','Q']),\n",
    "        ('2025-07-18', ['R']),\n",
    "        ('2025-07-21', ['R']),\n",
    "        ('2025-07-22', ['S']),\n",
    "        ('2025-07-23', ['T','U','V']),\n",
    "        ('2025-07-24', ['W','X','Y','Z']),\n",
    "    ],\n",
    "\n",
    "    # Sep-Oct 2025: 2-21 septiembre\n",
    "    '2025-09': [\n",
    "        ('2025-09-02', ['A']),\n",
    "        ('2025-09-03', ['B']),\n",
    "        ('2025-09-04', ['C']),\n",
    "        ('2025-09-05', ['C']),\n",
    "        ('2025-09-08', ['D','E','F']),\n",
    "        ('2025-09-09', ['G']),\n",
    "        ('2025-09-10', ['G']),\n",
    "        ('2025-09-11', ['H','I','J','K']),\n",
    "        ('2025-09-12', ['L']),\n",
    "        ('2025-09-15', ['M']),\n",
    "        ('2025-09-16', ['M']),\n",
    "        ('2025-09-17', ['N','Ñ','O']),\n",
    "        ('2025-09-18', ['P','Q']),\n",
    "        ('2025-09-19', ['R']),\n",
    "        ('2025-09-22', ['R','S','T','U','V','W','X','Y','Z']),\n",
    "    ],\n",
    "\n",
    "    # Nov-Dic 2025: 4-28 noviembre\n",
    "    '2025-11': [\n",
    "        ('2025-11-04', ['A']),\n",
    "        ('2025-11-05', ['B']),\n",
    "        ('2025-11-06', ['C']),\n",
    "        ('2025-11-07', ['C']),\n",
    "        ('2025-11-10', ['D','E','F']),\n",
    "        ('2025-11-11', ['G']),\n",
    "        ('2025-11-12', ['G']),\n",
    "        ('2025-11-13', ['H','I','J','K']),\n",
    "        ('2025-11-14', ['L']),\n",
    "        ('2025-11-17', ['M']),\n",
    "        ('2025-11-18', ['M']),\n",
    "        ('2025-11-19', ['N','Ñ','O']),\n",
    "        ('2025-11-20', ['P','Q']),\n",
    "        ('2025-11-21', ['R']),\n",
    "        ('2025-11-24', ['R']),\n",
    "        ('2025-11-25', ['S']),\n",
    "        ('2025-11-26', ['T','U','V']),\n",
    "        ('2025-11-28', ['W','X','Y','Z']),\n",
    "    ],\n",
    "\n",
    "    # Ene-Feb 2026: 5-28 enero\n",
    "    '2026-01': [\n",
    "        ('2026-01-05', ['A']),\n",
    "        ('2026-01-06', ['B']),\n",
    "        ('2026-01-07', ['C']),\n",
    "        ('2026-01-08', ['C']),\n",
    "        ('2026-01-09', ['D','E','F']),\n",
    "        ('2026-01-12', ['G']),\n",
    "        ('2026-01-13', ['G']),\n",
    "        ('2026-01-14', ['H','I','J','K']),\n",
    "        ('2026-01-15', ['L']),\n",
    "        ('2026-01-16', ['M']),\n",
    "        ('2026-01-19', ['M']),\n",
    "        ('2026-01-20', ['N','Ñ','O']),\n",
    "        ('2026-01-21', ['P','Q']),\n",
    "        ('2026-01-22', ['R']),\n",
    "        ('2026-01-23', ['R']),\n",
    "        ('2026-01-26', ['S']),\n",
    "        ('2026-01-27', ['T','U','V']),\n",
    "        ('2026-01-28', ['W','X','Y','Z']),\n",
    "    ],\n",
    "}\n",
    "\n",
    "programas = ['adultos_mayores', 'discapacidad', 'madres_trabajadoras']\n",
    "\n",
    "# OPCIÓN 1: Granular (programa_letra)\n",
    "holidays_granular = []\n",
    "for periodo, dias in calendarios_exactos.items():\n",
    "    for fecha_str, letras in dias:\n",
    "        fecha = pd.Timestamp(fecha_str)\n",
    "        for programa in programas:\n",
    "            for letra in letras:\n",
    "                holidays_granular.append({\n",
    "                    'ds': fecha,\n",
    "                    'holiday': f'{programa}_{letra}',\n",
    "                    'lower_window': 0,\n",
    "                    'upper_window': 3\n",
    "                })\n",
    "\n",
    "holidays_df_granular = pd.DataFrame(holidays_granular)\n",
    "\n",
    "# OPCIÓN 2: Agregado (solo programa)\n",
    "holidays_agregado = []\n",
    "for periodo, dias in calendarios_exactos.items():\n",
    "    for fecha_str, letras in dias:\n",
    "        fecha = pd.Timestamp(fecha_str)\n",
    "        for programa in programas:\n",
    "            holidays_agregado.append({\n",
    "                'ds': fecha,\n",
    "                'holiday': programa,\n",
    "                'lower_window': 0,\n",
    "                'upper_window': 3\n",
    "            })\n",
    "\n",
    "holidays_df_agregado = pd.DataFrame(holidays_agregado).drop_duplicates(subset=['ds','holiday'])\n",
    "\n",
    "print(\"HOLIDAYS GRANULAR (programa_letra):\")\n",
    "print(f\"  Total filas:  {len(holidays_df_granular)}\")\n",
    "print(f\"  Tipos únicos: {holidays_df_granular['holiday'].nunique()}\")\n",
    "print(f\"  Ejemplo: {holidays_df_granular['holiday'].unique()[:5]}\")\n",
    "\n",
    "print(\"\\nHOLIDAYS AGREGADO (solo programa):\")\n",
    "print(f\"  Total filas:  {len(holidays_df_agregado)}\")\n",
    "print(f\"  Tipos únicos: {holidays_df_agregado['holiday'].nunique()}\")\n",
    "print(f\"  Tipos: {holidays_df_agregado['holiday'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf121728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2.0 in c:\\Users\\diana.lara\\AppData\\Local\\miniconda3\\envs\\prophet_env\\Lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f4d161e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cajero JF000001: 571 observaciones desde 2024-07-01\n",
      "Rango: 2024-07-01 00:00:00 → 2026-01-22 00:00:00\n",
      "\n",
      "Holidays: granular\n",
      "  Eventos únicos: 81\n",
      "  Total registros: 1110\n",
      "\n",
      "================================================================================\n",
      "CONFIGURANDO MODELO NEURALPROPHET - TRADUCCIÓN DE PROPHET ÓPTIMO\n",
      "================================================================================\n",
      "\n",
      "Parámetros configurados:\n",
      "  trend_reg:           1.0\n",
      "  n_lags (AR):         60 ← NUEVO: memoria de 2 meses\n",
      "  ar_reg:              0.1 ← NUEVO: permite usar historial\n",
      "  yearly_seasonality:  52\n",
      "  seasonality_reg:     0.03\n",
      "  seasonality_mode:    multiplicative\n",
      "  n_forecasts:         30\n",
      "  epochs:              100\n",
      "  Holidays únicos:     81\n",
      "\n",
      "Agregando holidays como eventos...\n",
      "  Eventos agregados: 81\n",
      "\n",
      "Iniciando entrenamiento...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_14868\\2608036116.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# 5. ENTRENAR MODELO\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m    116\u001b[39m print(\u001b[33m\"\\nIniciando entrenamiento...\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m metrics = modelo.fit(df_cajero_eventos, freq=\u001b[33m'D'\u001b[39m)\n\u001b[32m    118\u001b[39m print(\u001b[33m\"Entrenamiento completado.\"\u001b[39m)\n\u001b[32m    119\u001b[39m \n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\diana.lara\\AppData\\Local\\miniconda3\\envs\\prophet_env\\Lib\\site-packages\\neuralprophet\\forecaster.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, df, freq, validation_df, epochs, batch_size, learning_rate, early_stopping, minimal, metrics, progress, checkpointing, continue_training, num_workers)\u001b[39m\n\u001b[32m   1016\u001b[39m         \u001b[38;5;66;03m# Pre-processing\u001b[39;00m\n\u001b[32m   1017\u001b[39m         \u001b[38;5;66;03m# Copy df and save list of unique time series IDs (the latter for global-local modelling if enabled)\u001b[39;00m\n\u001b[32m   1018\u001b[39m         df, _, _, self.id_list = df_utils.prep_or_copy_df(df)\n\u001b[32m   1019\u001b[39m         df = _check_dataframe(self, df, check_y=\u001b[38;5;28;01mTrue\u001b[39;00m, exogenous=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1020\u001b[39m         self.data_freq = df_utils.infer_frequency(df, n_lags=self.max_lags, freq=freq)\n\u001b[32m   1021\u001b[39m         df = _handle_missing_data(\n\u001b[32m   1022\u001b[39m             df=df,\n\u001b[32m   1023\u001b[39m             freq=self.data_freq,\n",
      "\u001b[32mc:\\Users\\diana.lara\\AppData\\Local\\miniconda3\\envs\\prophet_env\\Lib\\site-packages\\neuralprophet\\df_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(df, freq, n_lags, min_freq_percentage)\u001b[39m\n\u001b[32m   1395\u001b[39m     \"\"\"\n\u001b[32m   1396\u001b[39m     df, _, _, _ = prep_or_copy_df(df)\n\u001b[32m   1397\u001b[39m     freq_df = list()\n\u001b[32m   1398\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m df_name, df_i \u001b[38;5;28;01min\u001b[39;00m df.groupby(\u001b[33m\"ID\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1399\u001b[39m         freq_df.append(_infer_frequency(df_i, freq, min_freq_percentage))\n\u001b[32m   1400\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m len(set(freq_df)) != \u001b[32m1\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m n_lags > \u001b[32m0\u001b[39m:\n\u001b[32m   1401\u001b[39m         raise ValueError(\n\u001b[32m   1402\u001b[39m             \"One \u001b[38;5;28;01mor\u001b[39;00m more dataframes present different major frequencies, please make sure all dataframes present the \\\n",
      "\u001b[32mc:\\Users\\diana.lara\\AppData\\Local\\miniconda3\\envs\\prophet_env\\Lib\\site-packages\\neuralprophet\\df_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(df, freq, min_freq_percentage)\u001b[39m\n\u001b[32m   1268\u001b[39m         str\n\u001b[32m   1269\u001b[39m             Valid frequency tag according to major frequency.\n\u001b[32m   1270\u001b[39m \n\u001b[32m   1271\u001b[39m     \"\"\"\n\u001b[32m-> \u001b[39m\u001b[32m1272\u001b[39m     frequencies, distribution = get_freq_dist(df[\u001b[33m\"ds\"\u001b[39m])\n\u001b[32m   1273\u001b[39m     argmax_frequency = frequencies[np.argmax(distribution)]\n\u001b[32m   1274\u001b[39m \n\u001b[32m   1275\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.isnan(argmax_frequency):\n",
      "\u001b[32mc:\\Users\\diana.lara\\AppData\\Local\\miniconda3\\envs\\prophet_env\\Lib\\site-packages\\neuralprophet\\df_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(ds_col)\u001b[39m\n\u001b[32m   1148\u001b[39m     -------\n\u001b[32m   1149\u001b[39m         tuple\n\u001b[32m   1150\u001b[39m             numeric delta values (``ms``) \u001b[38;5;28;01mand\u001b[39;00m distribution of frequency counts\n\u001b[32m   1151\u001b[39m     \"\"\"\n\u001b[32m-> \u001b[39m\u001b[32m1152\u001b[39m     converted_ds = pd.to_datetime(ds_col, utc=\u001b[38;5;28;01mTrue\u001b[39;00m).view(dtype=np.int64)\n\u001b[32m   1153\u001b[39m     diff_ds = np.unique(converted_ds.diff(), return_counts=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m diff_ds\n",
      "\u001b[32mc:\\Users\\diana.lara\\AppData\\Local\\miniconda3\\envs\\prophet_env\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6202\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6203\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6204\u001b[39m         ):\n\u001b[32m   6205\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6206\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Series' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "from neuralprophet import NeuralProphet\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# 1. PREPARAR DATOS\n",
    "# ============================================================\n",
    "# Definir periodo de análisis y cajero a modelar\n",
    "fecha_inicio = '2024-07-01'  # Inicio post-periodo electoral\n",
    "cajero_test = 'JF000001'\n",
    "\n",
    "# Filtrar datos del cajero y periodo específico\n",
    "df_cajero = df[(df['fecha'] >= fecha_inicio) & (df['cajero'] == cajero_test)][['fecha', 'retiro']].copy()\n",
    "df_cajero.columns = ['ds', 'y']  # NeuralProphet también requiere columnas 'ds' e 'y'\n",
    "df_cajero = df_cajero.sort_values('ds').reset_index(drop=True)\n",
    "\n",
    "print(f\"Cajero {cajero_test}: {len(df_cajero)} observaciones desde {fecha_inicio}\")\n",
    "print(f\"Rango: {df_cajero['ds'].min()} → {df_cajero['ds'].max()}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. CONFIGURAR HOLIDAYS (FECHAS DE DISPERSIÓN)\n",
    "# ============================================================\n",
    "# Elegir nivel de granularidad de holidays:\n",
    "# - 'granular': 54 eventos (adultos_mayores_A, adultos_mayores_B, etc.)\n",
    "# - 'agregado': 3 eventos (adultos_mayores, discapacidad, madres_trabajadoras)\n",
    "holidays_type = 'granular' # agregado / granular\n",
    "holidays_usar = holidays_df_granular if holidays_type == 'granular' else holidays_df_agregado\n",
    "\n",
    "print(f\"\\nHolidays: {holidays_type}\")\n",
    "print(f\"  Eventos únicos: {holidays_usar['holiday'].nunique()}\")\n",
    "print(f\"  Total registros: {len(holidays_usar)}\")\n",
    "\n",
    "# NeuralProphet requiere holidays como columnas binarias en el dataframe\n",
    "df_cajero_eventos = df_cajero.copy()\n",
    "for holiday_name in holidays_usar['holiday'].unique():\n",
    "    fechas_holiday = holidays_usar[holidays_usar['holiday'] == holiday_name]['ds'].values\n",
    "    # Crear columna binaria: 1 si es día de ese holiday, 0 si no\n",
    "    df_cajero_eventos[holiday_name] = df_cajero_eventos['ds'].isin(fechas_holiday).astype(int)\n",
    "    # Aplicar ventana de efecto (lower_window=0, upper_window=3)\n",
    "    for i in range(1, 4):  # 3 días después\n",
    "        df_cajero_eventos.loc[\n",
    "            df_cajero_eventos['ds'].isin(fechas_holiday + pd.Timedelta(days=i)), \n",
    "            holiday_name\n",
    "        ] = 1\n",
    "\n",
    "# ============================================================\n",
    "# 3. CONFIGURAR MODELO NEURALPROPHET\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONFIGURANDO MODELO NEURALPROPHET - TRADUCCIÓN DE PROPHET ÓPTIMO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "modelo = NeuralProphet(\n",
    "    # --- TENDENCIA ---\n",
    "    growth='linear',  # Tendencia: 'linear'=crecimiento constante, 'discontinuous'=permite saltos/cambios abruptos\n",
    "    n_changepoints=6,                    # Número de puntos de cambio en la tendencia\n",
    "    changepoints_range=0.9,               # Rango donde se permiten changepoints\n",
    "    trend_reg=5,                        # Regularización de tendencia: 0.1=flexible/cambios bruscos, 1.0=moderado, 10=muy suave (inverso a Prophet)\n",
    "    \n",
    "    # --- COMPONENTE AUTORREGRESIVO (NUEVO - NO EXISTE EN PROPHET) ---\n",
    "    n_lags=150,                            # Memoria: usa últimos 60 días de retiros como features\n",
    "    ar_reg=0.01,                           # Regularización del AR: 0.01=muy flexible/usa historial agresivamente, 0.1=moderado, 1.0=restrictivo\n",
    "    \n",
    "    # --- ESTACIONALIDAD ANUAL ---\n",
    "    yearly_seasonality=52,                # Términos de Fourier para capturar ciclo anual (igual que Prophet)\n",
    "    seasonality_mode='additive',  # Modo: 'additive'=efectos constantes, 'multiplicative'=efectos escalan con nivel base\n",
    "    seasonality_reg=3,                 # Regularización de estacionalidad: 0.01=muy flexible, 0.1=moderado, 1.0=rígido (inverso a Prophet's seasonality_prior_scale)\n",
    "    \n",
    "    # --- ESTACIONALIDADES SEMANAL Y DIARIA ---\n",
    "    weekly_seasonality=True,              # Activada: puede haber patrón semanal leve\n",
    "    daily_seasonality=False,              # Desactivada: no hay patrón intra-día en datos diarios\n",
    "    \n",
    "    # --- PREDICCIÓN MULTI-HORIZONTE ---\n",
    "    n_forecasts=30,                       # Predecir 30 días hacia adelante simultáneamente\n",
    "    \n",
    "    # --- ENTRENAMIENTO ---\n",
    "    epochs=100,                           # Iteraciones de entrenamiento\n",
    "    batch_size=32,  # Tamaño de batch para gradiente: 16=lento/preciso, 32=balanceado, 64=rápido/menos preciso\n",
    "    learning_rate=0.01,  # Tasa de aprendizaje: 0.001=lento/estable, 0.01=balanceado, 0.1=rápido/inestable\n",
    "    \n",
    "    # --- OTROS ---\n",
    "    loss_func='Huber',  # Función de pérdida: 'MSE'=sensible a outliers, 'Huber'=robusta a outliers, 'MAE'=muy robusta\n",
    "    normalize='standardize',  # Normalización: 'off'=sin normalizar, 'minmax'=escala 0-1, 'standardize'=media 0 y std 1\n",
    "    impute_missing=True  # Rellena gaps: True=interpola valores faltantes, False=mantiene NaN (puede causar errores)\n",
    ")\n",
    "\n",
    "print(f\"\\nParámetros configurados:\")\n",
    "print(f\"  trend_reg:           {1.0}\")\n",
    "print(f\"  n_lags (AR):         {60} ← NUEVO: memoria de 2 meses\")\n",
    "print(f\"  ar_reg:              {0.1} ← NUEVO: permite usar historial\")\n",
    "print(f\"  yearly_seasonality:  {52}\")\n",
    "print(f\"  seasonality_reg:     {0.03}\")\n",
    "print(f\"  seasonality_mode:    multiplicative\")\n",
    "print(f\"  n_forecasts:         {30}\")\n",
    "print(f\"  epochs:              {100}\")\n",
    "print(f\"  Holidays únicos:     {holidays_usar['holiday'].nunique()}\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. AGREGAR HOLIDAYS (EVENTOS) AL MODELO\n",
    "# ============================================================\n",
    "print(\"\\nAgregando holidays como eventos...\")\n",
    "for holiday_name in holidays_usar['holiday'].unique():\n",
    "    modelo = modelo.add_events(\n",
    "        holiday_name,\n",
    "        lower_window=0,                   # Efecto comienza el día del evento\n",
    "        upper_window=3,                   # Efecto dura 3 días después\n",
    "        regularization=0.1                # Regularización de eventos\n",
    "    )\n",
    "print(f\"  Eventos agregados: {len(holidays_usar['holiday'].unique())}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. ENTRENAR MODELO\n",
    "# ============================================================\n",
    "print(\"\\nIniciando entrenamiento...\")\n",
    "metrics = modelo.fit(df_cajero_eventos, freq='D')\n",
    "print(\"Entrenamiento completado.\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. GENERAR PREDICCIONES\n",
    "# ============================================================\n",
    "forecast = modelo.predict(df_cajero_eventos)\n",
    "\n",
    "# NeuralProphet con n_forecasts=30 genera yhat1, yhat2, ..., yhat30\n",
    "# Usamos yhat1 (predicción a 1 día) para comparar con valores históricos\n",
    "merged = df_cajero.merge(forecast[['ds', 'yhat1']], on='ds').dropna(subset=['yhat1'])\n",
    "\n",
    "# ============================================================\n",
    "# 7. EVALUAR DESEMPEÑO\n",
    "# ============================================================\n",
    "# Convertir predicciones negativas a cero\n",
    "print(\"\\nAplicando corrección: predicciones negativas → 0\")\n",
    "negativos_antes = (merged['yhat1'] < 0).sum()\n",
    "merged['yhat1'] = merged['yhat1'].clip(lower=0)\n",
    "print(f\"  Predicciones negativas corregidas: {negativos_antes}\")\n",
    "\n",
    "# Calcular métricas\n",
    "r2 = r2_score(merged['y'], merged['yhat1'])\n",
    "mae = mean_absolute_error(merged['y'], merged['yhat1'])\n",
    "rmse = np.sqrt(((merged['yhat1'] - merged['y'])**2).mean())\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"RESULTADOS:\")\n",
    "print(f\"  R² (coeficiente de determinación): {r2:.4f}\")\n",
    "print(f\"     → % de varianza explicada por el modelo\")\n",
    "print(f\"  MAE (error absoluto medio):        ${mae:,.0f}\")\n",
    "print(f\"     → Error promedio en pesos\")\n",
    "print(f\"  RMSE (raíz del error cuadrático): ${rmse:,.0f}\")\n",
    "print(f\"     → Penaliza más los errores grandes\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# 8. GRAFICAR AJUSTE\n",
    "# ============================================================\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "# Serie real (negro)\n",
    "ax.plot(df_cajero['ds'], df_cajero['y'], \n",
    "        label='Real', color='black', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "# Predicción (rojo)\n",
    "ax.plot(merged['ds'], merged['yhat1'], \n",
    "        label=f'Predicción (R²={r2:.4f})', color='red', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "# Marcar fechas de dispersión (líneas verticales azules)\n",
    "for fecha in holidays_usar['ds'].unique():\n",
    "    if fecha >= df_cajero['ds'].min() and fecha <= df_cajero['ds'].max():\n",
    "        ax.axvline(fecha, color='blue', alpha=0.2, linewidth=0.5)\n",
    "\n",
    "ax.set_title(f'NeuralProphet | Cajero {cajero_test} | Desde {fecha_inicio}', \n",
    "             fontsize=14)\n",
    "ax.set_xlabel('Fecha')\n",
    "ax.set_ylabel('Retiro ($)')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 9. GRAFICAR COMPONENTES MANUALMENTE\n",
    "# ============================================================\n",
    "\n",
    "# Filtrar filas sin NaN en componentes\n",
    "if holidays_type == 'granular':\n",
    "    # Para granular: solo graficar componentes agregados (trend, season, events_additive)\n",
    "    componentes_a_graficar = ['trend', 'season_yearly', 'season_weekly', 'events_additive']\n",
    "else:\n",
    "    # Para agregado: incluir eventos individuales\n",
    "    componentes_a_graficar = ['trend', 'season_yearly', 'season_weekly', 'events_additive', \n",
    "                              'event_adultos_mayores', 'event_discapacidad', 'event_madres_trabajadoras']\n",
    "\n",
    "forecast_limpio = forecast.dropna(subset=componentes_a_graficar)\n",
    "\n",
    "print(f\"\\nFilas con componentes completos: {len(forecast_limpio)} de {len(forecast)}\")\n",
    "\n",
    "if len(forecast_limpio) > 0:\n",
    "    fig, axes = plt.subplots(len(componentes_a_graficar), 1, figsize=(20, 4*len(componentes_a_graficar)))\n",
    "    \n",
    "    for idx, componente in enumerate(componentes_a_graficar):\n",
    "        axes[idx].plot(forecast_limpio['ds'], forecast_limpio[componente], \n",
    "                      linewidth=1.5, color='steelblue')\n",
    "        axes[idx].set_title(f'Componente: {componente}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_ylabel('Efecto')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        axes[idx].axhline(0, color='black', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "    \n",
    "    axes[-1].set_xlabel('Fecha')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"Componentes graficados exitosamente.\")\n",
    "else:\n",
    "    print(\"⚠️ No hay suficientes datos sin NaN para graficar componentes.\")\n",
    "    print(\"Esto puede pasar si n_lags es muy grande vs el tamaño del dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4add3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install neuralprophet>=0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5729d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralprophet import NeuralProphet\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# 1. PREPARAR DATOS\n",
    "# ============================================================\n",
    "# Definir periodo de análisis y cajero a modelar\n",
    "fecha_inicio = '2024-07-01'  # Inicio post-periodo electoral\n",
    "cajero_test = 'JF000001'\n",
    "\n",
    "# Filtrar datos del cajero y periodo específico\n",
    "df_cajero = df[(df['fecha'] >= fecha_inicio) & (df['cajero'] == cajero_test)][['fecha', 'retiro']].copy()\n",
    "df_cajero.columns = ['ds', 'y']  # NeuralProphet también requiere columnas 'ds' e 'y'\n",
    "df_cajero = df_cajero.sort_values('ds').reset_index(drop=True)\n",
    "\n",
    "print(f\"Cajero {cajero_test}: {len(df_cajero)} observaciones desde {fecha_inicio}\")\n",
    "print(f\"Rango: {df_cajero['ds'].min()} → {df_cajero['ds'].max()}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. CONFIGURAR HOLIDAYS (FECHAS DE DISPERSIÓN)\n",
    "# ============================================================\n",
    "# Elegir nivel de granularidad de holidays:\n",
    "# - 'granular': 54 eventos (adultos_mayores_A, adultos_mayores_B, etc.)\n",
    "# - 'agregado': 3 eventos (adultos_mayores, discapacidad, madres_trabajadoras)\n",
    "holidays_type = 'granular' # agregado / granular\n",
    "holidays_usar = holidays_df_granular if holidays_type == 'granular' else holidays_df_agregado\n",
    "\n",
    "print(f\"\\nHolidays: {holidays_type}\")\n",
    "print(f\"  Eventos únicos: {holidays_usar['holiday'].nunique()}\")\n",
    "print(f\"  Total registros: {len(holidays_usar)}\")\n",
    "\n",
    "# NeuralProphet requiere holidays como columnas binarias en el dataframe\n",
    "df_cajero_eventos = df_cajero.copy()\n",
    "for holiday_name in holidays_usar['holiday'].unique():\n",
    "    fechas_holiday = holidays_usar[holidays_usar['holiday'] == holiday_name]['ds'].values\n",
    "    # Crear columna binaria: 1 si es día de ese holiday, 0 si no\n",
    "    df_cajero_eventos[holiday_name] = df_cajero_eventos['ds'].isin(fechas_holiday).astype(int)\n",
    "    # Aplicar ventana de efecto (lower_window=0, upper_window=3)\n",
    "    for i in range(1, 4):  # 3 días después\n",
    "        df_cajero_eventos.loc[\n",
    "            df_cajero_eventos['ds'].isin(fechas_holiday + pd.Timedelta(days=i)), \n",
    "            holiday_name\n",
    "        ] = 1\n",
    "\n",
    "# ============================================================\n",
    "# 3. CONFIGURAR MODELO NEURALPROPHET\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONFIGURANDO MODELO NEURALPROPHET - TRADUCCIÓN DE PROPHET ÓPTIMO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "modelo = NeuralProphet(\n",
    "    # --- TENDENCIA ---\n",
    "    growth='linear',  # Tendencia: 'linear'=crecimiento constante, 'discontinuous'=permite saltos/cambios abruptos\n",
    "    n_changepoints=6,  # Número de puntos de cambio en la tendencia\n",
    "    changepoints_range=0.9,  # Rango donde se permiten changepoints\n",
    "    trend_reg=5,  # Regularización de tendencia: 0.1=flexible/cambios bruscos, 1.0=moderado, 10=muy suave (inverso a Prophet)\n",
    "    \n",
    "    # --- COMPONENTE AUTORREGRESIVO (NUEVO - NO EXISTE EN PROPHET) ---\n",
    "    n_lags=150,  # Memoria: usa últimos N días de retiros como features\n",
    "    ar_reg=0.01,  # Regularización del AR: 0.01=muy flexible/usa historial agresivamente, 0.1=moderado, 1.0=restrictivo\n",
    "    \n",
    "    # --- ESTACIONALIDAD ANUAL ---\n",
    "    yearly_seasonality=52,  # Términos de Fourier para capturar ciclo anual\n",
    "    seasonality_mode='additive',  # Modo: 'additive'=efectos constantes, 'multiplicative'=efectos escalan con nivel base\n",
    "    seasonality_reg=3,  # Regularización de estacionalidad: 0.01=muy flexible, 0.1=moderado, 1.0=rígido (inverso a Prophet's seasonality_prior_scale)\n",
    "    \n",
    "    # --- ESTACIONALIDADES SEMANAL Y DIARIA ---\n",
    "    weekly_seasonality=True,  # Activada: puede haber patrón semanal leve\n",
    "    daily_seasonality=False,  # Desactivada: no hay patrón intra-día en datos diarios\n",
    "    \n",
    "    # --- PREDICCIÓN MULTI-HORIZONTE ---\n",
    "    n_forecasts=30,  # Predecir 30 días hacia adelante simultáneamente\n",
    "    \n",
    "    # --- ENTRENAMIENTO ---\n",
    "    epochs=100,  # Iteraciones de entrenamiento\n",
    "    batch_size=32,  # Tamaño de batch para gradiente: 16=lento/preciso, 32=balanceado, 64=rápido/menos preciso\n",
    "    learning_rate=0.01,  # Tasa de aprendizaje: 0.001=lento/estable, 0.01=balanceado, 0.1=rápido/inestable\n",
    "    \n",
    "    # --- OTROS ---\n",
    "    loss_func='Huber',  # Función de pérdida: 'MSE'=sensible a outliers, 'Huber'=robusta a outliers, 'MAE'=muy robusta\n",
    "    normalize='standardize',  # Normalización: 'off'=sin normalizar, 'minmax'=escala 0-1, 'standardize'=media 0 y std 1\n",
    "    impute_missing=True  # Rellena gaps: True=interpola valores faltantes, False=mantiene NaN (puede causar errores)\n",
    ")\n",
    "\n",
    "print(f\"\\nParámetros configurados:\")\n",
    "print(f\"  n_changepoints:      6\")\n",
    "print(f\"  trend_reg:           5\")\n",
    "print(f\"  n_lags (AR):         150 ← NUEVO: memoria de 150 días\")\n",
    "print(f\"  ar_reg:              0.01\")\n",
    "print(f\"  yearly_seasonality:  52\")\n",
    "print(f\"  seasonality_reg:     3\")\n",
    "print(f\"  seasonality_mode:    additive\")\n",
    "print(f\"  n_forecasts:         30\")\n",
    "print(f\"  epochs:              100\")\n",
    "print(f\"  learning_rate:       0.01\")\n",
    "print(f\"  batch_size:          32\")\n",
    "print(f\"  Holidays únicos:     {holidays_usar['holiday'].nunique()}\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. AGREGAR HOLIDAYS (EVENTOS) AL MODELO\n",
    "# ============================================================\n",
    "print(\"\\nAgregando holidays como eventos...\")\n",
    "for holiday_name in holidays_usar['holiday'].unique():\n",
    "    modelo = modelo.add_events(\n",
    "        holiday_name,\n",
    "        lower_window=0,  # Efecto comienza el día del evento\n",
    "        upper_window=3,  # Efecto dura 3 días después\n",
    "        regularization=0.1  # Regularización de eventos\n",
    "    )\n",
    "print(f\"  Eventos agregados: {len(holidays_usar['holiday'].unique())}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. ENTRENAR MODELO\n",
    "# ============================================================\n",
    "print(\"\\nIniciando entrenamiento...\")\n",
    "metrics = modelo.fit(df_cajero_eventos, freq='D')\n",
    "print(\"Entrenamiento completado.\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. GENERAR PREDICCIONES\n",
    "# ============================================================\n",
    "forecast = modelo.predict(df_cajero_eventos)\n",
    "\n",
    "# NeuralProphet con n_forecasts=30 genera yhat1, yhat2, ..., yhat30\n",
    "# Usamos yhat1 (predicción a 1 día) para comparar con valores históricos\n",
    "merged = df_cajero.merge(forecast[['ds', 'yhat1']], on='ds').dropna(subset=['yhat1'])\n",
    "\n",
    "# ============================================================\n",
    "# 7. EVALUAR DESEMPEÑO\n",
    "# ============================================================\n",
    "# Convertir predicciones negativas a cero\n",
    "print(\"\\nAplicando corrección: predicciones negativas → 0\")\n",
    "negativos_antes = (merged['yhat1'] < 0).sum()\n",
    "merged['yhat1'] = merged['yhat1'].clip(lower=0)\n",
    "print(f\"  Predicciones negativas corregidas: {negativos_antes}\")\n",
    "\n",
    "# Calcular métricas\n",
    "r2 = r2_score(merged['y'], merged['yhat1'])\n",
    "mae = mean_absolute_error(merged['y'], merged['yhat1'])\n",
    "rmse = np.sqrt(((merged['yhat1'] - merged['y'])**2).mean())\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"RESULTADOS:\")\n",
    "print(f\"  R² (coeficiente de determinación): {r2:.4f}\")\n",
    "print(f\"     → % de varianza explicada por el modelo\")\n",
    "print(f\"  MAE (error absoluto medio):        ${mae:,.0f}\")\n",
    "print(f\"     → Error promedio en pesos\")\n",
    "print(f\"  RMSE (raíz del error cuadrático): ${rmse:,.0f}\")\n",
    "print(f\"     → Penaliza más los errores grandes\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# 8. GRAFICAR AJUSTE\n",
    "# ============================================================\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "# Serie real (negro)\n",
    "ax.plot(df_cajero['ds'], df_cajero['y'], \n",
    "        label='Real', color='black', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "# Predicción (rojo)\n",
    "ax.plot(merged['ds'], merged['yhat1'], \n",
    "        label=f'Predicción (R²={r2:.4f})', color='red', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "# Marcar fechas de dispersión (líneas verticales azules)\n",
    "for fecha in holidays_usar['ds'].unique():\n",
    "    if fecha >= df_cajero['ds'].min() and fecha <= df_cajero['ds'].max():\n",
    "        ax.axvline(fecha, color='blue', alpha=0.2, linewidth=0.5)\n",
    "\n",
    "ax.set_title(f'NeuralProphet | Cajero {cajero_test} | Desde {fecha_inicio}', \n",
    "             fontsize=14)\n",
    "ax.set_xlabel('Fecha')\n",
    "ax.set_ylabel('Retiro ($)')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 9. GRAFICAR COMPONENTES MANUALMENTE\n",
    "# ============================================================\n",
    "\n",
    "# Filtrar filas sin NaN en componentes\n",
    "if holidays_type == 'granular':\n",
    "    componentes_a_graficar = ['trend', 'season_yearly', 'season_weekly', 'events_additive']\n",
    "else:\n",
    "    componentes_a_graficar = ['trend', 'season_yearly', 'season_weekly', 'events_additive', \n",
    "                              'event_adultos_mayores', 'event_discapacidad', 'event_madres_trabajadoras']\n",
    "\n",
    "forecast_limpio = forecast.dropna(subset=componentes_a_graficar)\n",
    "\n",
    "print(f\"\\nFilas con componentes completos: {len(forecast_limpio)} de {len(forecast)}\")\n",
    "\n",
    "if len(forecast_limpio) > 0:\n",
    "    fig, axes = plt.subplots(len(componentes_a_graficar), 1, figsize=(20, 4*len(componentes_a_graficar)))\n",
    "    \n",
    "    for idx, componente in enumerate(componentes_a_graficar):\n",
    "        axes[idx].plot(forecast_limpio['ds'], forecast_limpio[componente], \n",
    "                      linewidth=1.5, color='steelblue')\n",
    "        axes[idx].set_title(f'Componente: {componente}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_ylabel('Efecto')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        axes[idx].axhline(0, color='black', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "    \n",
    "    axes[-1].set_xlabel('Fecha')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"Componentes graficados exitosamente.\")\n",
    "else:\n",
    "    print(\"No hay suficientes datos sin NaN para graficar componentes.\")\n",
    "    print(\"Esto puede pasar si n_lags es muy grande vs el tamaño del dataset.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS:\")\n",
    "print(\"  Comparación Prophet vs NeuralProphet:\")\n",
    "print(f\"    Prophet R²:        0.8175\")\n",
    "print(f\"    NeuralProphet R²:  {r2:.4f}\")\n",
    "if r2 > 0.8175:\n",
    "    print(f\"    ✓ MEJORA: +{(r2-0.8175)*100:.2f} puntos porcentuales\")\n",
    "    print(\"    → Componente AR y no linealidad ayudaron\")\n",
    "else:\n",
    "    print(f\"    ✗ NO MEJORÓ: {(r2-0.8175)*100:.2f} puntos porcentuales\")\n",
    "    print(\"    → Prophet ya captura bien el patrón, quedarse con él\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prophet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
